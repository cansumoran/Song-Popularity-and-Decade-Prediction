{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN_decade_tfidf","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b7b42c8d0b3f4647a3a221607d066658":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b73ccbad908849c3ac65a9bcc5472dcb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_51d9ed4bf1d641f89c80ce2e381b5b6f","IPY_MODEL_30f3f216c6594cf19242e3e4e94d766d","IPY_MODEL_fc777bf80c3040609c6596aa2721fb99"]}},"b73ccbad908849c3ac65a9bcc5472dcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51d9ed4bf1d641f89c80ce2e381b5b6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4ba105101e904a1381fe9256ddb8e32e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1b71b42d8884334b06c7a85d59527ba"}},"30f3f216c6594cf19242e3e4e94d766d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0a91047319c24ccd849b04a1d360c24f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":25078,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25078,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_593ebfb231bc40c0aede19eff6bfe242"}},"fc777bf80c3040609c6596aa2721fb99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1f7553832b2f45759e22d83a394aa1a2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25078/25078 [00:00&lt;00:00,  7.24it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_22d4dbfffc33423cbcd689c704f1be28"}},"4ba105101e904a1381fe9256ddb8e32e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e1b71b42d8884334b06c7a85d59527ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a91047319c24ccd849b04a1d360c24f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"593ebfb231bc40c0aede19eff6bfe242":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1f7553832b2f45759e22d83a394aa1a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"22d4dbfffc33423cbcd689c704f1be28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Mount device#"],"metadata":{"id":"E3g1SKfOTKfP"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"JPgQj9-eKSHe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640520829984,"user_tz":-180,"elapsed":10647,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"outputId":"89efd3ea-09b9-4fae-865f-887eb6934a9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YCSSK67mKTix","executionInfo":{"status":"ok","timestamp":1640520829985,"user_tz":-180,"elapsed":24,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"outputId":"48281444-8c21-4112-e8e7-9c63d10483a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vDLHPL6yKZ4f","executionInfo":{"status":"ok","timestamp":1640520829986,"user_tz":-180,"elapsed":16,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"outputId":"e19be1c5-3a95-4441-e229-75779773f447"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"markdown","source":["#Import#"],"metadata":{"id":"kmxq_EyeTQkG"}},{"cell_type":"code","source":["from collections import Counter\n","import re\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm_notebook\n","import tensorflow as tf\n","\n","import nltk\n","\n","from tensorflow.keras import regularizers, initializers, optimizers, callbacks\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from keras.utils.np_utils import to_categorical\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"metadata":{"id":"wJ5FT714My5-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Define Constants#"],"metadata":{"id":"CbUsa7GdTbrP"}},{"cell_type":"code","source":["MAX_NB_WORDS = 100000    # max no. of words for tokenizer\n","MAX_SEQUENCE_LENGTH = 100 # max length of each entry (sentence), including padding\n","EMBEDDING_DIM = 100      # embedding dimensions for word vectors (word2vec/GloVe)\n","GLOVE_DIR = \"glove.6B.\"+str(EMBEDDING_DIM)+\"d.txt\""],"metadata":{"id":"G4KuqfpoM0g0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Load Data#"],"metadata":{"id":"UN7AaqX8Tqby"}},{"cell_type":"code","source":["train = pd.read_csv('BALANCED.csv') #change to dataset here\n","y = train['period'].values\n","lyrics_train = train['lyrics']\n","lyrics_train = list(lyrics_train)\n","\n","labels = [60, 70, 80, 90, 0, 10]"],"metadata":{"id":"lFkg-ACiTj2g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(lyrics_train))"],"metadata":{"id":"fY63OksTTkgt","executionInfo":{"status":"ok","timestamp":1640520872495,"user_tz":-180,"elapsed":12,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"344ee378-688d-4c99-d347-126339e5eb15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["25078\n"]}]},{"cell_type":"code","source":["texts = [] \n","y_final = []\n","num = 0\n","\n","for line in tqdm_notebook(lyrics_train): \n","    if type(line) != float:\n","      texts.append(line)\n","      y_final.append(y[num])\n","    num += 1\n","\n","y = np.array(y_final)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100,"referenced_widgets":["b7b42c8d0b3f4647a3a221607d066658","b73ccbad908849c3ac65a9bcc5472dcb","51d9ed4bf1d641f89c80ce2e381b5b6f","30f3f216c6594cf19242e3e4e94d766d","fc777bf80c3040609c6596aa2721fb99","4ba105101e904a1381fe9256ddb8e32e","e1b71b42d8884334b06c7a85d59527ba","0a91047319c24ccd849b04a1d360c24f","593ebfb231bc40c0aede19eff6bfe242","1f7553832b2f45759e22d83a394aa1a2","22d4dbfffc33423cbcd689c704f1be28"]},"id":"13zo9E6kTuAy","executionInfo":{"status":"ok","timestamp":1640520872875,"user_tz":-180,"elapsed":389,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"outputId":"3859640f-a0ae-43aa-95f9-4c9d417fed57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \"\"\"\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7b42c8d0b3f4647a3a221607d066658","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/25078 [00:00<?, ?it/s]"]},"metadata":{}}]},{"cell_type":"code","source":["print('Sample data:', texts[753], y[753])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AelTN4U5TwK_","executionInfo":{"status":"ok","timestamp":1640520872876,"user_tz":-180,"elapsed":7,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"outputId":"6f1dbbbc-783b-40e9-fee2-9b275692e7dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample data: read news today oh boy lucky man made grade though news rather sad well laugh saw photograph blew mind car notice light changed crowd people stood stared seen face nobody really sure house lord 60.0\n"]}]},{"cell_type":"markdown","source":["#Tokenize#"],"metadata":{"id":"PKeoHssuT2R9"}},{"cell_type":"code","source":["for i, ex in enumerate(texts):\n","  if (type(ex) == float):\n","    print(i, ex)"],"metadata":{"id":"GRAlkJk4XtXR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## TF-IDF"],"metadata":{"id":"WNlSHksO4j4Q"}},{"cell_type":"code","source":["vectorizer = TfidfVectorizer( max_features=MAX_NB_WORDS)\n","vectorizer.fit(texts)\n","\n","vector = vectorizer.transform(texts)\n","print(type(vector))"],"metadata":{"id":"Z1U-DV_FzTo_","executionInfo":{"status":"ok","timestamp":1640520879694,"user_tz":-180,"elapsed":6320,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a668c999-5d5c-42d8-c1e9-efd00e80d1f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'scipy.sparse.csr.csr_matrix'>\n"]}]},{"cell_type":"markdown","source":["#Padding"],"metadata":{"id":"bGlatWYFT7go"}},{"cell_type":"code","source":["data = vector.toarray()\n","print('Shape of data tensor:', data.shape)\n","print('Shape of label tensor:', y.shape)"],"metadata":{"id":"LuJGW3o1T9Bo","executionInfo":{"status":"ok","timestamp":1640520884013,"user_tz":-180,"elapsed":4323,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1bda8db5-b3e6-412a-e4ae-a7775b183d25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of data tensor: (25062, 38585)\n","Shape of label tensor: (25062,)\n"]}]},{"cell_type":"code","source":["indices = np.arange(data.shape[0])\n","np.random.shuffle(indices)\n","data = data[indices]\n","labels = y[indices]"],"metadata":{"id":"LWrUgqr7VXuM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert to one hot encoding \n","one_hot_labels = []\n","for lab in labels:\n","  lab_arr = [0, 0, 0, 0, 0, 0] #60, 70, 80, 90, 0, 10\n","  if lab > 50:\n","    lab_arr[int((lab - 60) / 10)] = 1\n","  elif lab == 0:\n","    lab_arr[4] = 1\n","  else:\n","    lab_arr[5] = 1\n","\n","  one_hot_labels.append(lab_arr)\n","\n","one_hot_labels = np.array(one_hot_labels)\n","print(one_hot_labels[0])"],"metadata":{"id":"m3J9h3abdr4p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640426616321,"user_tz":-180,"elapsed":24,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"outputId":"64192ab9-e804-403b-fbdf-6fb078f1eaf6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 0 0 0 0]\n"]}]},{"cell_type":"code","source":["print(type(data))"],"metadata":{"id":"e-vF-9TP8wAR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640426616322,"user_tz":-180,"elapsed":22,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"outputId":"9035eeb5-4b46-40e7-ea0d-8ba4c1025cc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n"]}]},{"cell_type":"code","source":["print('Tokenized sentences: \\n', data[2])\n","print('Label: \\n', labels[2], one_hot_labels[2])"],"metadata":{"id":"cOCsVfSwVkgo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640426616322,"user_tz":-180,"elapsed":19,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"outputId":"1ef4d448-d0d0-4686-fdca-d75164c765dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized sentences: \n"," [0. 0. 0. ... 0. 0. 0.]\n","Label: \n"," 60.0 [1 0 0 0 0 0]\n"]}]},{"cell_type":"code","source":["print(data.shape)\n","print(one_hot_labels.shape)"],"metadata":{"id":"h74ugOQ7VlcI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640426616322,"user_tz":-180,"elapsed":16,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"outputId":"2772fb58-15df-4d25-ba5f-0a257e059d1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1000, 4360)\n","(1000, 6)\n"]}]},{"cell_type":"code","source":["# Converting our labels into numpy arrays\n","lyrics = np.array(data)\n","labels = np.array(one_hot_labels)"],"metadata":{"id":"Qy3aajVONA-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(lyrics[:20])\n","print(labels[:20])"],"metadata":{"id":"ZoKHQok3UVUl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640426616323,"user_tz":-180,"elapsed":13,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"outputId":"778da46c-5b21-47a4-aec3-0856dd5e72b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","[[1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]\n"," [1 0 0 0 0 0]]\n"]}]},{"cell_type":"markdown","source":["#Partition the Data (train, val, test)#"],"metadata":{"id":"OOQFhP1rYOxv"}},{"cell_type":"code","source":["split_frac = 0.7 # 70% train, 30% test(val + test)\n","split_id = int(split_frac * len(lyrics))\n","train_lyrics, test_lyrics = lyrics[:split_id], lyrics[split_id:]\n","train_labels, test_labels = labels[:split_id], labels[split_id:]"],"metadata":{"id":"B18pZdJrYOCD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_labels.shape)\n","print(train_lyrics.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9yWALQ6x4c0","executionInfo":{"status":"ok","timestamp":1640426616324,"user_tz":-180,"elapsed":11,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}},"outputId":"4d80e5e3-cb98-4d9a-9738-043e73c4007f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(700, 6)\n","(700, 4360)\n"]}]},{"cell_type":"code","source":["split_frac = 0.5 # 50% validation, 50% test\n","split_id = int(split_frac * len(test_lyrics))\n","val_lyrics, test_lyrics = test_lyrics[:split_id], test_lyrics[split_id:]\n","val_labels, test_labels = test_labels[:split_id], test_labels[split_id:]"],"metadata":{"id":"2JKHQ_NMNC5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch.nn as nn\n","\n","train_data = TensorDataset(torch.from_numpy(train_lyrics), torch.from_numpy(train_labels))\n","val_data = TensorDataset(torch.from_numpy(val_lyrics), torch.from_numpy(val_labels))\n","test_data = TensorDataset(torch.from_numpy(test_lyrics), torch.from_numpy(test_labels))\n","\n","batch_size = 16 \n","hidden = 64\n","epochs = 30 \n","lr=0.0001\n","dropout=0.5\n","\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n","val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size, drop_last=True)\n","test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)"],"metadata":{"id":"7FikYb4TNG_r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n","is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"RRssUNuPNI4G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SentimentNet(nn.Module):\n","    def __init__(self,\n","                 weight_matrix=None,\n","                 vocab_size=None, \n","                 output_size=1,  \n","                 hidden_dim=512, \n","                 embedding_dim=400, \n","                 n_layers=1, \n","                 dropout_prob=0.5):\n","        super(SentimentNet, self).__init__()\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.hidden_dim = hidden_dim\n","        # initialize the representation to pass to the LSTM\n","        self.embedding, embedding_dim = self.init_embedding(\n","            vocab_size, \n","            embedding_dim, \n","            weight_matrix)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n","                            dropout=dropout_prob, batch_first=True)\n","        # dropout\n","        self.dropout = nn.Dropout(dropout_prob)\n","        # fully connected layer\n","        self.fc = nn.Linear(hidden_dim, output_size)\n","        self.softmax = nn.Softmax(dim = -1)\n","        \n","    def forward(self, x, hidden):\n","        # forward pass of the network\n","        batch_size = x.size(0)\n","        # transform input\n","        embeds = self.embedding(x)\n","        # run input embedding + hidden state through model\n","        lstm_out, hidden = self.lstm(embeds, hidden)\n","        # reshape\n","        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n","        # dropout certain pct of connections\n","        out = self.dropout(lstm_out)\n","        # fully connected layer\n","        out = self.fc(out)\n","        # connect to 6 outputs (one_hot_encoding)\n","        # activation function\n","        out = self.softmax(out)\n","        out = out.view(batch_size, int(out.shape[0] / batch_size), out.shape[1])\n","        out = out[:,-1]\n","        # return the output and the hidden state\n","        return out, hidden, lstm_out\n","    \n","    def init_embedding(self, vocab_size, embedding_dim, weight_matrix):\n","        # initializes the embedding\n","        if weight_matrix is None:\n","            if vocab_size is None:\n","                raise ValueError('If no weight matrix, need a vocab size')\n","            # if embedding is a size, initialize trainable\n","            return(nn.Embedding(vocab_size, embedding_dim),\n","                   embedding_dim)\n","        else:\n","            # otherwise use matrix as pretrained\n","            weights = torch.FloatTensor(weight_matrix)\n","            return(nn.Embedding.from_pretrained(weights),\n","                  weights.shape[1])\n","    \n","    def init_hidden(self, batch_size):\n","        # initializes the hidden state\n","        hidden = (torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device),\n","                  torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device))\n","        return hidden"],"metadata":{"id":"idkjoUlMqRm4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_params = {'weight_matrix': None,\n","                'vocab_size': data.shape[1] + 1,\n","               'output_size': 6,\n","               'hidden_dim': hidden,\n","               'n_layers': 2,\n","               'embedding_dim': EMBEDDING_DIM,\n","               'dropout_prob': dropout}\n","model = SentimentNet(**model_params)\n","\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)"],"metadata":{"id":"SBInTg7vNNz-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["counter = 0\n","print_every = 10\n","clip = 5\n","valid_loss_min = np.Inf\n","\n","model.train()\n","\n","train_losses = []\n","val_losses = []\n","train_acc = []\n","val_acc = []\n","\n","for i in range(epochs):\n","    print(\"Epoch\")\n","    h = model.init_hidden(batch_size)\n","    train_correct = 0\n","    val_correct = 0\n","    calculated = 0\n","    train_loss = []\n","    val_loss = []\n","    train_count = 0\n","    val_count = 0\n","\n","    periods = [0, 0, 0, 0, 0, 0]\n","    periods_gt = [0, 0, 0, 0, 0, 0]\n","    \n","    for inputs, labels in train_loader:\n","        inputs = inputs.clone().detach().to(torch.int64)\n","        counter += 1\n","        h = tuple([e.data for e in h])\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        model.zero_grad()\n","        output, h, lstm_out = model(inputs, h)\n","        loss = criterion(output.squeeze(), labels.float())\n","\n","        train_loss.append(loss.item())\n","\n","        for j, ex in enumerate(output):\n","          train_count += 1\n","          gt_label = torch.argmax(labels[j].float()) \n","          pred_label = torch.argmax(ex.squeeze())\n","\n","          periods[pred_label] += 1\n","          periods_gt[gt_label] += 1\n","\n","          if pred_label.eq(gt_label):\n","            train_correct += 1\n","\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        \n","    val_h = model.init_hidden(batch_size)\n","    model.eval()\n","\n","    for inp, lab in val_loader:\n","        inp = inp.clone().detach().to(torch.int64)\n","        val_h = tuple([each.data for each in val_h])\n","        inp, lab = inp.to(device), lab.to(device)\n","        out, val_h, _ = model(inp, val_h)\n","        loss_val = criterion(out.squeeze(), lab.float())\n","\n","        val_loss.append(loss_val.item())\n","\n","        for j, ex in enumerate(out):\n","          val_count += 1\n","          gt_label = torch.argmax(lab[j].float()) \n","          pred_label = torch.argmax(ex.squeeze())\n","\n","          if pred_label.eq(gt_label):\n","            val_correct += 1\n","        \n","    model.train()\n","\n","    print(\"Epoch: {}/{}\".format(i+1, epochs),\n","          \"Loss: {:.6f}\".format(np.mean(train_loss)),\n","          \"Val Loss: {:.6f}\".format(np.mean(val_loss)),\n","          \"Acc: {:.6f}\".format(train_correct/train_count),\n","          \"Val Acc: {:.6f}\".format(val_correct/val_count))\n","    print(train_correct)\n","    print(train_count)\n","    \n","    if np.mean(val_loss) <= valid_loss_min:\n","        torch.save(model.state_dict(), './state_dict_' + str(EMBEDDING_DIM) + '.pt')\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model.'.format(valid_loss_min,np.mean(val_loss)))\n","        valid_loss_min = np.mean(val_loss)\n","\n","    train_losses.append(np.mean(train_loss))\n","    val_losses.append(np.mean(val_loss))\n","    train_acc.append(train_correct/train_count)\n","    val_acc.append(val_correct/val_count)\n","    print(periods)\n","    print(periods_gt)"],"metadata":{"id":"YaF4M1-fNOTp","colab":{"base_uri":"https://localhost:8080/","height":868},"outputId":"ced067a4-3ec7-46f6-b9e2-6bf30f956653","executionInfo":{"status":"error","timestamp":1640428137343,"user_tz":-180,"elapsed":172279,"user":{"displayName":"Irmak Hatip","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10318308407840366918"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch\n","Epoch: 1/30 Loss: 1.703726 Val Loss: 1.613644 Acc: 0.984012 Val Acc: 1.000000\n","677\n","688\n","Validation loss decreased (inf --> 1.613644).  Saving model.\n","[677, 6, 1, 4, 0, 0]\n","[688, 0, 0, 0, 0, 0]\n","Epoch\n","Epoch: 2/30 Loss: 1.455494 Val Loss: 1.223298 Acc: 1.000000 Val Acc: 1.000000\n","688\n","688\n","Validation loss decreased (1.613644 --> 1.223298).  Saving model.\n","[688, 0, 0, 0, 0, 0]\n","[688, 0, 0, 0, 0, 0]\n","Epoch\n","Epoch: 3/30 Loss: 1.162593 Val Loss: 1.092557 Acc: 1.000000 Val Acc: 1.000000\n","688\n","688\n","Validation loss decreased (1.223298 --> 1.092557).  Saving model.\n","[688, 0, 0, 0, 0, 0]\n","[688, 0, 0, 0, 0, 0]\n","Epoch\n","Epoch: 4/30 Loss: 1.090637 Val Loss: 1.067114 Acc: 1.000000 Val Acc: 1.000000\n","688\n","688\n","Validation loss decreased (1.092557 --> 1.067114).  Saving model.\n","[688, 0, 0, 0, 0, 0]\n","[688, 0, 0, 0, 0, 0]\n","Epoch\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-8d3a59c903b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-5eb2eef876f5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# run input embedding + hidden state through model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m# reshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 692\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[" # Loading the best model\n","model.load_state_dict(torch.load('./state_dict_' + str(EMBEDDING_DIM) + '.pt'))\n","\n","test_losses = []\n","periods = [0, 0, 0, 0, 0, 0]\n","gt_periods = [0, 0, 0, 0, 0, 0]\n","num_correct = 0\n","h = model.init_hidden(batch_size)\n","\n","model.eval()\n","for inputs, labels in test_loader:\n","    inputs = inputs.clone().detach().to(torch.int64)\n","    h = tuple([each.data for each in h])\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    output, h, _ = model(inputs, h)\n","    test_loss = criterion(output.squeeze(), labels.float())\n","    test_losses.append(test_loss.item())\n","\n","    for i, ex in enumerate(output):\n","      gt_label = torch.argmax(labels[i].float()) \n","      pred_label = torch.argmax(ex.squeeze())\n","\n","      periods[pred_label] += 1\n","      gt_periods[gt_label] += 1\n","\n","      if pred_label.eq(gt_label):\n","        num_correct += 1\n","\n","print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n","test_acc = num_correct/len(test_loader.dataset)\n","print(\"Test accuracy: {:.3f}\".format(test_acc))\n","print(num_correct)\n","print(len(test_loader.dataset))\n","print(periods)\n","print(gt_periods)"],"metadata":{"id":"Am3NGxfsNSYc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline \n","\n","\n","plt.figure(figsize=(10,5))\n","plt.title(\"Training and Validation Loss for Embeddigns = \" + str(EMBEDDING_DIM))\n","plt.plot(val_losses,label=\"val\")\n","plt.plot(train_losses,label=\"train\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.savefig(\"tfidf_loss_\" + str(epochs)+\"_\"+ str(batch_size) + \"_\" + str(lr)+ \"_\" + str(EMBEDDING_DIM) + \"_\" + str(hidden) + \".jpg\")\n","plt.show()"],"metadata":{"id":"KVmTjU5RgHcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,5))\n","plt.title(\"Training and Validation Accuracy for Embeddigns = \" + str(EMBEDDING_DIM))\n","plt.plot(val_acc,label=\"val\")\n","plt.plot(train_acc,label=\"train\")\n","plt.xlabel(\"epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.savefig(\"tfidf_acc_\" + str(epochs)+\"_\"+ str(batch_size) + \"_\" + str(lr)+ \"_\" + str(EMBEDDING_DIM) + \"_\" + str(hidden) + \".jpg\")\n","plt.show()"],"metadata":{"id":"5FgOaW0mUpri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"vdjEIN_2YoAi"},"execution_count":null,"outputs":[]}]}